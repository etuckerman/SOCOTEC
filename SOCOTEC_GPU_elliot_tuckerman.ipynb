{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyMwF5uCMQvXb25CCXip2Z+w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "50e96932174d40238701e042202bd9be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d845fe2d937a41439f5a76a8afced2bd",
              "IPY_MODEL_151c9bef718c496495278046fef0da42",
              "IPY_MODEL_a33783aa24904bfaba4275a8e9a14310"
            ],
            "layout": "IPY_MODEL_2448456c676149fca6c4d0a2b6bb6dd1"
          }
        },
        "d845fe2d937a41439f5a76a8afced2bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90a51a28dd8d43e5bbc24fe135433473",
            "placeholder": "​",
            "style": "IPY_MODEL_e7afced176dd4aa1937146fc966ba8d2",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "151c9bef718c496495278046fef0da42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_475917b794cc4ba588f0f3d59c22ef4c",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_524dc35d9ea24c67a58b55c731503631",
            "value": 2
          }
        },
        "a33783aa24904bfaba4275a8e9a14310": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e39d4d42d7b49309865152aac3560ed",
            "placeholder": "​",
            "style": "IPY_MODEL_47bc2599a761449e9967a795a448eefb",
            "value": " 2/2 [00:10&lt;00:00,  4.85s/it]"
          }
        },
        "2448456c676149fca6c4d0a2b6bb6dd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90a51a28dd8d43e5bbc24fe135433473": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7afced176dd4aa1937146fc966ba8d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "475917b794cc4ba588f0f3d59c22ef4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "524dc35d9ea24c67a58b55c731503631": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8e39d4d42d7b49309865152aac3560ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47bc2599a761449e9967a795a448eefb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/etuckerman/SOCOTEC/blob/main/SOCOTEC_GPU_elliot_tuckerman.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkCUTOUXqJRq",
        "outputId": "d2e88401-896a-4b30-8b0d-453fcf7e323a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
            "    Setting a new token will erase the existing one.\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: read).\n",
            "The token `SOCOTEC` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `SOCOTEC`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for GPU availability\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUnzndM9py19",
        "outputId": "cd40fb50-e6b1-4521-efa6-794b4e725185"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Dec  9 18:29:59 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P0              53W / 400W |  10257MiB / 40960MiB |      0%      Default |\n",
            "|                                         |                      |             Disabled |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "!pip install -q transformers torch accelerate datasets openai\n",
        "!pip install -q bitsandbytes\n",
        "\n",
        "import torch\n",
        "import transformers\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "import re"
      ],
      "metadata": {
        "id": "Y2O4YZQCp3wo"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement function library as specified\n",
        "def add(a, b): return a + b\n",
        "def square(a): return a ** 2\n",
        "def cube(a): return a ** 3\n",
        "def greet(name): return f\"Hello, {name}!\"\n",
        "\n",
        "# Function mapping dictionary\n",
        "FUNCTION_MAPPING = {\n",
        "    'add': add,\n",
        "    'square': square,\n",
        "    'cube': cube,\n",
        "    'greet': greet\n",
        "}"
      ],
      "metadata": {
        "id": "1DaCRGrqp5Ql"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create synthetic training dataset\n",
        "training_data = [\n",
        "    {\"input\": \"What is the sum of 1 and 2?\", \"output\": \"add(1, 2)\"}\n",
        "]\n",
        "\n",
        "# Additional diverse prompts\n",
        "# Comprehensive test cases covering all functions\n",
        "test_cases = training_data + [\n",
        "    # Organized test cases with diverse scenarios\n",
        "    # Basic addition scenarios\n",
        "    {\"input\": \"What is the sum of 7 and 3?\", \"output\": \"add(7, 3)\"},\n",
        "    {\"input\": \"Add 10 and 15\", \"output\": \"add(10, 15)\"},\n",
        "    {\"input\": \"How much is 20 plus 22?\", \"output\": \"add(20, 22)\"},\n",
        "    {\"input\": \"Add 50 and 30\", \"output\": \"add(50, 30)\"},\n",
        "    {\"input\": \"What is 18 plus 27?\", \"output\": \"add(18, 27)\"},\n",
        "\n",
        "    # Square function scenarios\n",
        "    {\"input\": \"Calculate the square of 5\", \"output\": \"square(5)\"},\n",
        "    {\"input\": \"Square of 6\", \"output\": \"square(6)\"},\n",
        "    {\"input\": \"Square 7\", \"output\": \"square(7)\"},\n",
        "    {\"input\": \"Square of 4\", \"output\": \"square(4)\"},\n",
        "    {\"input\": \"Square of 8\", \"output\": \"square(8)\"},\n",
        "\n",
        "    # Cube function scenarios\n",
        "    {\"input\": \"What's the cube of 2?\", \"output\": \"cube(2)\"},\n",
        "    {\"input\": \"Cube the number 4\", \"output\": \"cube(4)\"},\n",
        "    {\"input\": \"Cube of 3\", \"output\": \"cube(3)\"},\n",
        "    {\"input\": \"Cube 5\", \"output\": \"cube(5)\"},\n",
        "    {\"input\": \"Cube of 6\", \"output\": \"cube(6)\"},\n",
        "\n",
        "    # Greeting scenarios\n",
        "    {\"input\": \"Greet John\", \"output\": \"greet('John')\"},\n",
        "    {\"input\": \"Say hello to Sarah\", \"output\": \"greet('Sarah')\"},\n",
        "    {\"input\": \"Greet Emily\", \"output\": \"greet('Emily')\"},\n",
        "    {\"input\": \"Greet Michael\", \"output\": \"greet('Michael')\"},\n",
        "\n",
        "    # BONUS: Multi-function scenarios (to demonstrate potential)\n",
        "    {\"input\": \"Add the square of 3 to 10\", \"output\": \"add(square(3), 10)\"},\n",
        "    {\"input\": \"Greet the person who got the cube of 2\", \"output\": \"greet('cube(2)')\"}\n",
        "]"
      ],
      "metadata": {
        "id": "OoHsr-2Sp6VD"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_prompt(input_text):\n",
        "    return f\"\"\"You are an expert at converting natural language to precise Python function calls using ONLY these predefined functions:\n",
        "- add(a, b): Returns the sum of a and b\n",
        "- square(a): Returns a squared\n",
        "- cube(a): Returns a cubed\n",
        "- greet(name): Returns a greeting for the given name\n",
        "\n",
        "IMPORTANT: ONLY use these exact function names and signatures.\n",
        "\n",
        "Convert the following input to EXACTLY the correct function call:\n",
        "Input: {input_text}\n",
        "Correct Function Call: \"\"\"\n",
        "\n",
        "import ast  # Import ast module for argument parsing\n",
        "\n",
        "def generate_function_call(model, tokenizer, input_text, max_length=150):\n",
        "    prompt = format_prompt(input_text)\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_length=max_length,\n",
        "        num_return_sequences=1,\n",
        "        do_sample=True,\n",
        "        temperature=0.1\n",
        "    )\n",
        "\n",
        "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    # Improved regular expression for function call extraction\n",
        "    function_call_match = re.search(r'Correct Function Call:\\s*(\\w+\\(.*?\\))', generated_text)\n",
        "\n",
        "    if function_call_match:\n",
        "        function_call = function_call_match.group(1).strip()\n",
        "\n",
        "        # Preserve original quotes\n",
        "        # ... (consider keeping quotes as generated)\n",
        "\n",
        "        # More robust argument parsing using ast.literal_eval\n",
        "        try:\n",
        "            args = ast.literal_eval(function_call.split(\"(\")[1].rstrip(\")\"))\n",
        "        except (SyntaxError, ValueError):\n",
        "            args = []\n",
        "\n",
        "        if not re.match(r'^(add|square|cube|greet)\\(', function_call):\n",
        "            return None\n",
        "\n",
        "        return function_call\n",
        "    return None\n",
        "\n",
        "\n",
        "def execute_function_call(function_call):\n",
        "    try:\n",
        "        match = re.match(r'(\\w+)\\((.*?)\\)', function_call)\n",
        "        if not match:\n",
        "            return \"Invalid function call format\"\n",
        "\n",
        "        func_name, args_str = match.groups()\n",
        "\n",
        "        # More robust argument parsing\n",
        "        args = []\n",
        "        for arg in re.findall(r\"'[^']*'|\\\"[^\\\"]*\\\"|[^,\\s]+\", args_str):\n",
        "            arg = arg.strip(\"'\\\"\")\n",
        "            try:\n",
        "                arg = int(arg) if arg.isdigit() else arg\n",
        "            except ValueError:\n",
        "                pass\n",
        "            args.append(arg)\n",
        "\n",
        "        if func_name in FUNCTION_MAPPING:\n",
        "            return FUNCTION_MAPPING[func_name](*args)\n",
        "        else:\n",
        "            return f\"Unsupported function: {func_name}\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error executing function: {str(e)}\"\n",
        "\n",
        "def evaluate_model(model, tokenizer, test_cases):\n",
        "    results = []\n",
        "    for case in test_cases:\n",
        "        function_call = generate_function_call(model, tokenizer, case['input'])\n",
        "        expected_call = case['output']\n",
        "\n",
        "        result = {\n",
        "            'input': case['input'],\n",
        "            'generated_call': function_call,\n",
        "            'expected_call': expected_call,\n",
        "            'call_match': function_call == expected_call\n",
        "        }\n",
        "\n",
        "        if result['call_match']:\n",
        "            try:\n",
        "                result['execution_result'] = execute_function_call(function_call)\n",
        "            except Exception as e:\n",
        "                result['execution_result'] = str(e)\n",
        "\n",
        "        results.append(result)\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "ZikRxjR1p7Ia"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model setup\n",
        "model_name = \"mistralai/Mistral-7B-v0.1\"\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    device_map=\"auto\",\n",
        "    load_in_8bit=True,\n",
        "    torch_dtype=torch.float16\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "50e96932174d40238701e042202bd9be",
            "d845fe2d937a41439f5a76a8afced2bd",
            "151c9bef718c496495278046fef0da42",
            "a33783aa24904bfaba4275a8e9a14310",
            "2448456c676149fca6c4d0a2b6bb6dd1",
            "90a51a28dd8d43e5bbc24fe135433473",
            "e7afced176dd4aa1937146fc966ba8d2",
            "475917b794cc4ba588f0f3d59c22ef4c",
            "524dc35d9ea24c67a58b55c731503631",
            "8e39d4d42d7b49309865152aac3560ed",
            "47bc2599a761449e9967a795a448eefb"
          ]
        },
        "id": "9LuSMAXtp9pS",
        "outputId": "9ac8a64c-298d-4f61-fb6c-d861edf49a66"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "50e96932174d40238701e042202bd9be"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run evaluation\n",
        "evaluation_results = evaluate_model(model, tokenizer, test_cases)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xinh49aFp-qL",
        "outputId": "5a1afdab-09d4-4519-c2ac-be3bed11e5f1"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:2097: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print results\n",
        "for result in evaluation_results:\n",
        "    print(f\"Input: {result['input']}\")\n",
        "    print(f\"Generated Call: {result['generated_call']}\")\n",
        "    print(f\"Expected Call: {result['expected_call']}\")\n",
        "    print(f\"Call Match: {result['call_match']}\")\n",
        "    if result.get('execution_result'):\n",
        "        print(f\"Execution Result: {result['execution_result']}\")\n",
        "    print(\"---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0Ua1vSWp_u7",
        "outputId": "ef84c555-5535-4cd0-c78c-8e7f3fa03c97"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: What is the sum of 1 and 2?\n",
            "Generated Call: add(1, 2)\n",
            "Expected Call: add(1, 2)\n",
            "Call Match: True\n",
            "Execution Result: 3\n",
            "---\n",
            "Input: What is the sum of 7 and 3?\n",
            "Generated Call: add(7, 3)\n",
            "Expected Call: add(7, 3)\n",
            "Call Match: True\n",
            "Execution Result: 10\n",
            "---\n",
            "Input: Add 10 and 15\n",
            "Generated Call: add(10, 15)\n",
            "Expected Call: add(10, 15)\n",
            "Call Match: True\n",
            "Execution Result: 25\n",
            "---\n",
            "Input: How much is 20 plus 22?\n",
            "Generated Call: add(20, 22)\n",
            "Expected Call: add(20, 22)\n",
            "Call Match: True\n",
            "Execution Result: 42\n",
            "---\n",
            "Input: Add 50 and 30\n",
            "Generated Call: add(50, 30)\n",
            "Expected Call: add(50, 30)\n",
            "Call Match: True\n",
            "Execution Result: 80\n",
            "---\n",
            "Input: What is 18 plus 27?\n",
            "Generated Call: add(18, 27)\n",
            "Expected Call: add(18, 27)\n",
            "Call Match: True\n",
            "Execution Result: 45\n",
            "---\n",
            "Input: Calculate the square of 5\n",
            "Generated Call: square(5)\n",
            "Expected Call: square(5)\n",
            "Call Match: True\n",
            "Execution Result: 25\n",
            "---\n",
            "Input: Square of 6\n",
            "Generated Call: square(6)\n",
            "Expected Call: square(6)\n",
            "Call Match: True\n",
            "Execution Result: 36\n",
            "---\n",
            "Input: Square 7\n",
            "Generated Call: square(7)\n",
            "Expected Call: square(7)\n",
            "Call Match: True\n",
            "Execution Result: 49\n",
            "---\n",
            "Input: Square of 4\n",
            "Generated Call: square(4)\n",
            "Expected Call: square(4)\n",
            "Call Match: True\n",
            "Execution Result: 16\n",
            "---\n",
            "Input: Square of 8\n",
            "Generated Call: square(8)\n",
            "Expected Call: square(8)\n",
            "Call Match: True\n",
            "Execution Result: 64\n",
            "---\n",
            "Input: What's the cube of 2?\n",
            "Generated Call: cube(2)\n",
            "Expected Call: cube(2)\n",
            "Call Match: True\n",
            "Execution Result: 8\n",
            "---\n",
            "Input: Cube the number 4\n",
            "Generated Call: cube(4)\n",
            "Expected Call: cube(4)\n",
            "Call Match: True\n",
            "Execution Result: 64\n",
            "---\n",
            "Input: Cube of 3\n",
            "Generated Call: cube(3)\n",
            "Expected Call: cube(3)\n",
            "Call Match: True\n",
            "Execution Result: 27\n",
            "---\n",
            "Input: Cube 5\n",
            "Generated Call: cube(5)\n",
            "Expected Call: cube(5)\n",
            "Call Match: True\n",
            "Execution Result: 125\n",
            "---\n",
            "Input: Cube of 6\n",
            "Generated Call: cube(6)\n",
            "Expected Call: cube(6)\n",
            "Call Match: True\n",
            "Execution Result: 216\n",
            "---\n",
            "Input: Greet John\n",
            "Generated Call: greet('John')\n",
            "Expected Call: greet('John')\n",
            "Call Match: True\n",
            "Execution Result: Hello, John!\n",
            "---\n",
            "Input: Say hello to Sarah\n",
            "Generated Call: greet('Sarah')\n",
            "Expected Call: greet('Sarah')\n",
            "Call Match: True\n",
            "Execution Result: Hello, Sarah!\n",
            "---\n",
            "Input: Greet Emily\n",
            "Generated Call: greet('Emily')\n",
            "Expected Call: greet('Emily')\n",
            "Call Match: True\n",
            "Execution Result: Hello, Emily!\n",
            "---\n",
            "Input: Greet Michael\n",
            "Generated Call: greet(\"Michael\")\n",
            "Expected Call: greet('Michael')\n",
            "Call Match: False\n",
            "---\n",
            "Input: Add the square of 3 to 10\n",
            "Generated Call: add(square(3)\n",
            "Expected Call: add(square(3), 10)\n",
            "Call Match: False\n",
            "---\n",
            "Input: Greet the person who got the cube of 2\n",
            "Generated Call: greet(cube(2)\n",
            "Expected Call: greet('cube(2)')\n",
            "Call Match: False\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd  # Import DataFrame support\n",
        "\n",
        "\n",
        "def evaluate_model_with_dataframe(model, tokenizer, test_cases):\n",
        "    \"\"\"Evaluates the model's predictions and stores results in a DataFrame.\"\"\"\n",
        "    results = []\n",
        "\n",
        "    # Process each test case\n",
        "    for case in test_cases:\n",
        "        function_call = generate_function_call(model, tokenizer, case['input'])\n",
        "        expected_call = case['output']\n",
        "\n",
        "        # Check match and execution\n",
        "        call_match = function_call == expected_call\n",
        "        execution_result = None\n",
        "\n",
        "        if call_match:\n",
        "            try:\n",
        "                execution_result = execute_function_call(function_call)\n",
        "            except Exception as e:\n",
        "                execution_result = str(e)\n",
        "\n",
        "        # Store results in a dictionary\n",
        "        results.append({\n",
        "            \"input\": case['input'],\n",
        "            \"generated_call\": function_call,\n",
        "            \"expected_call\": expected_call,\n",
        "            \"call_match\": call_match,\n",
        "            \"execution_result\": execution_result\n",
        "        })\n",
        "\n",
        "    # Convert results to DataFrame\n",
        "    df = pd.DataFrame(results)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# Run the evaluation and create the DataFrame\n",
        "evaluation_df = evaluate_model_with_dataframe(model, tokenizer, test_cases)\n",
        "\n",
        "# Display results from DataFrame\n",
        "for index, row in evaluation_df.iterrows():\n",
        "    print(f\"Input: {row['input']}\")\n",
        "    print(f\"Generated Call: {row['generated_call']}\")\n",
        "    print(f\"Expected Call: {row['expected_call']}\")\n",
        "    print(f\"Call Match: {row['call_match']}\")\n",
        "    if row['execution_result'] is not None:\n",
        "        print(f\"Execution Result: {row['execution_result']}\")\n",
        "    print(\"---\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ehbxh7Jxx8GG",
        "outputId": "e0cc6544-f11a-4601-9d62-62e7319e2b87"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: What is the sum of 1 and 2?\n",
            "Generated Call: add(1, 2)\n",
            "Expected Call: add(1, 2)\n",
            "Call Match: True\n",
            "Execution Result: 3\n",
            "---\n",
            "Input: What is the sum of 7 and 3?\n",
            "Generated Call: add(7, 3)\n",
            "Expected Call: add(7, 3)\n",
            "Call Match: True\n",
            "Execution Result: 10\n",
            "---\n",
            "Input: Add 10 and 15\n",
            "Generated Call: add(10, 15)\n",
            "Expected Call: add(10, 15)\n",
            "Call Match: True\n",
            "Execution Result: 25\n",
            "---\n",
            "Input: How much is 20 plus 22?\n",
            "Generated Call: None\n",
            "Expected Call: add(20, 22)\n",
            "Call Match: False\n",
            "---\n",
            "Input: Add 50 and 30\n",
            "Generated Call: add(50, 30)\n",
            "Expected Call: add(50, 30)\n",
            "Call Match: True\n",
            "Execution Result: 80\n",
            "---\n",
            "Input: What is 18 plus 27?\n",
            "Generated Call: add(18, 27)\n",
            "Expected Call: add(18, 27)\n",
            "Call Match: True\n",
            "Execution Result: 45\n",
            "---\n",
            "Input: Calculate the square of 5\n",
            "Generated Call: square(5)\n",
            "Expected Call: square(5)\n",
            "Call Match: True\n",
            "Execution Result: 25\n",
            "---\n",
            "Input: Square of 6\n",
            "Generated Call: square(6)\n",
            "Expected Call: square(6)\n",
            "Call Match: True\n",
            "Execution Result: 36\n",
            "---\n",
            "Input: Square 7\n",
            "Generated Call: square(7)\n",
            "Expected Call: square(7)\n",
            "Call Match: True\n",
            "Execution Result: 49\n",
            "---\n",
            "Input: Square of 4\n",
            "Generated Call: square(4)\n",
            "Expected Call: square(4)\n",
            "Call Match: True\n",
            "Execution Result: 16\n",
            "---\n",
            "Input: Square of 8\n",
            "Generated Call: square(8)\n",
            "Expected Call: square(8)\n",
            "Call Match: True\n",
            "Execution Result: 64\n",
            "---\n",
            "Input: What's the cube of 2?\n",
            "Generated Call: cube(2)\n",
            "Expected Call: cube(2)\n",
            "Call Match: True\n",
            "Execution Result: 8\n",
            "---\n",
            "Input: Cube the number 4\n",
            "Generated Call: cube(4)\n",
            "Expected Call: cube(4)\n",
            "Call Match: True\n",
            "Execution Result: 64\n",
            "---\n",
            "Input: Cube of 3\n",
            "Generated Call: cube(3)\n",
            "Expected Call: cube(3)\n",
            "Call Match: True\n",
            "Execution Result: 27\n",
            "---\n",
            "Input: Cube 5\n",
            "Generated Call: cube(5)\n",
            "Expected Call: cube(5)\n",
            "Call Match: True\n",
            "Execution Result: 125\n",
            "---\n",
            "Input: Cube of 6\n",
            "Generated Call: cube(6)\n",
            "Expected Call: cube(6)\n",
            "Call Match: True\n",
            "Execution Result: 216\n",
            "---\n",
            "Input: Greet John\n",
            "Generated Call: greet('John')\n",
            "Expected Call: greet('John')\n",
            "Call Match: True\n",
            "Execution Result: Hello, John!\n",
            "---\n",
            "Input: Say hello to Sarah\n",
            "Generated Call: greet(\"Sarah\")\n",
            "Expected Call: greet('Sarah')\n",
            "Call Match: False\n",
            "---\n",
            "Input: Greet Emily\n",
            "Generated Call: greet(\"Emily\")\n",
            "Expected Call: greet('Emily')\n",
            "Call Match: False\n",
            "---\n",
            "Input: Greet Michael\n",
            "Generated Call: greet(\"Michael\")\n",
            "Expected Call: greet('Michael')\n",
            "Call Match: False\n",
            "---\n",
            "Input: Add the square of 3 to 10\n",
            "Generated Call: add(square(3)\n",
            "Expected Call: add(square(3), 10)\n",
            "Call Match: False\n",
            "---\n",
            "Input: Greet the person who got the cube of 2\n",
            "Generated Call: greet(cube(2)\n",
            "Expected Call: greet('cube(2)')\n",
            "Call Match: False\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "DmUZRSo--Lc7",
        "outputId": "120978cb-7b5c-4c6c-8172-db0e646ee64c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         input generated_call expected_call  call_match  \\\n",
              "0  What is the sum of 1 and 2?      add(1, 2)     add(1, 2)        True   \n",
              "1  What is the sum of 7 and 3?      add(7, 3)     add(7, 3)        True   \n",
              "2                Add 10 and 15    add(10, 15)   add(10, 15)        True   \n",
              "3      How much is 20 plus 22?           None   add(20, 22)       False   \n",
              "4                Add 50 and 30    add(50, 30)   add(50, 30)        True   \n",
              "5          What is 18 plus 27?    add(18, 27)   add(18, 27)        True   \n",
              "6    Calculate the square of 5      square(5)     square(5)        True   \n",
              "7                  Square of 6      square(6)     square(6)        True   \n",
              "8                     Square 7      square(7)     square(7)        True   \n",
              "9                  Square of 4      square(4)     square(4)        True   \n",
              "\n",
              "  execution_result  \n",
              "0                3  \n",
              "1               10  \n",
              "2               25  \n",
              "3             None  \n",
              "4               80  \n",
              "5               45  \n",
              "6               25  \n",
              "7               36  \n",
              "8               49  \n",
              "9               16  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-51a51187-d350-4603-b1e0-f0cd64840889\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>generated_call</th>\n",
              "      <th>expected_call</th>\n",
              "      <th>call_match</th>\n",
              "      <th>execution_result</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the sum of 1 and 2?</td>\n",
              "      <td>add(1, 2)</td>\n",
              "      <td>add(1, 2)</td>\n",
              "      <td>True</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the sum of 7 and 3?</td>\n",
              "      <td>add(7, 3)</td>\n",
              "      <td>add(7, 3)</td>\n",
              "      <td>True</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Add 10 and 15</td>\n",
              "      <td>add(10, 15)</td>\n",
              "      <td>add(10, 15)</td>\n",
              "      <td>True</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How much is 20 plus 22?</td>\n",
              "      <td>None</td>\n",
              "      <td>add(20, 22)</td>\n",
              "      <td>False</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Add 50 and 30</td>\n",
              "      <td>add(50, 30)</td>\n",
              "      <td>add(50, 30)</td>\n",
              "      <td>True</td>\n",
              "      <td>80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>What is 18 plus 27?</td>\n",
              "      <td>add(18, 27)</td>\n",
              "      <td>add(18, 27)</td>\n",
              "      <td>True</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Calculate the square of 5</td>\n",
              "      <td>square(5)</td>\n",
              "      <td>square(5)</td>\n",
              "      <td>True</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Square of 6</td>\n",
              "      <td>square(6)</td>\n",
              "      <td>square(6)</td>\n",
              "      <td>True</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Square 7</td>\n",
              "      <td>square(7)</td>\n",
              "      <td>square(7)</td>\n",
              "      <td>True</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Square of 4</td>\n",
              "      <td>square(4)</td>\n",
              "      <td>square(4)</td>\n",
              "      <td>True</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-51a51187-d350-4603-b1e0-f0cd64840889')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-51a51187-d350-4603-b1e0-f0cd64840889 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-51a51187-d350-4603-b1e0-f0cd64840889');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-eb2952e4-e28b-4087-a04c-73b3d63d2994\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-eb2952e4-e28b-4087-a04c-73b3d63d2994')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-eb2952e4-e28b-4087-a04c-73b3d63d2994 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "evaluation_df",
              "summary": "{\n  \"name\": \"evaluation_df\",\n  \"rows\": 22,\n  \"fields\": [\n    {\n      \"column\": \"input\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 22,\n        \"samples\": [\n          \"What is the sum of 1 and 2?\",\n          \"Cube of 3\",\n          \"Square 7\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"generated_call\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 21,\n        \"samples\": [\n          \"add(1, 2)\",\n          \"greet(\\\"Emily\\\")\",\n          \"greet('John')\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"expected_call\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 22,\n        \"samples\": [\n          \"add(1, 2)\",\n          \"cube(3)\",\n          \"square(7)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"call_match\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"execution_result\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 14,\n        \"samples\": [\n          8,\n          125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0F5dDd9M-umb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}